# 🤖 AI Chatbot: Gemini API + Local LLMs with Ollama

This is a powerful and flexible AI chatbot that connects to **Google's Gemini API** for advanced AI capabilities and also supports running **local large language models (LLMs)** using **[Ollama](https://ollama.com)** — all in a single, seamless interface.

## 🚀 Key Features

- 🌐 **Cloud AI with Gemini**: Get intelligent responses from Gemini Pro using your API key.
- 🏠 **Offline AI with Ollama**: Run local LLMs like LLaMA, Mistral, and more using Ollama — perfect for privacy, speed, or offline access.
- 🔄 **Switch Engines Easily**: Choose between Gemini or local models.
- 💡 **Lightweight and Customizable**: Designed to be easily extended, integrated, or modified for your own use case.

## ⚙️ How to Use

1. Clone this repository.
2. Install the required dependencies.
3. Add your `GEM_API` in a `.env` file.
4. Install and start a local model using [Ollama](https://ollama.com).
5. Run the chatbot using either Gemini or a local LLM:

✨ Why It's Unique
Unlike most chatbots that rely solely on cloud APIs, this project empowers you to run local models without an internet connection, 
offering complete control over your data and experience — all from a single tool.
